{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d53d06d-bd9a-4d21-b9a5-6a76b32e3116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Install Correct Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be7e905c-ba00-4665-b8e9-bd239aca40ff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Packages"
    }
   },
   "outputs": [],
   "source": [
    "%pip install streamlit sentence-transformers pandas numpy mlflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94e9c394-5d7d-4fa7-81bc-5263b4eecd86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Restart python to make sure packages are loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cafd5dc-16c2-45de-aac8-7a88a3510540",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restart Python"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e557c27-73c6-4bb6-83eb-e41c4bcc9f0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Setup MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "636f5c28-3e71-45db-a4ce-0f9a76619c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.deployments\n",
    "\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "\n",
    "try:\n",
    "    endpoints = client.list_endpoints()\n",
    "    print(\"Endpoints\")\n",
    "    for endpoint in endpoints:\n",
    "        print(endpoint['name'])\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test foundation model\n",
    "try:\n",
    "    response = client.predict(\n",
    "        endpoint=\"databricks-llama-4-maverick\",  # Adjust based on available models\n",
    "        inputs={\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n",
    "            \"max_tokens\": 100,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "    )\n",
    "    print(\"Foundation model test successful!\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Foundation model test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e4d4076-c4a7-4159-8251-02a51cdfee29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import mlflow\n",
    "import mlflow.deployments\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Configuration for Databricks Native Setup\n",
    "class Config:\n",
    "    # Databricks foundation model endpoints (adjust based on what's available)\n",
    "    FOUNDATION_MODEL_ENDPOINT = \"databricks-gemma-3-12b\"  # or available model\n",
    "    EMBEDDING_MODEL = \"databricks-bge-large-en\"  # Use Databricks embedding model if available\n",
    "    FALLBACK_EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"  # Fallback to sentence-transformers\n",
    "    MAX_CONTEXT_LENGTH = 3000\n",
    "    DATABRICKS_HOST = None  # Will be auto-detected\n",
    "    DATABRICKS_TOKEN = None  # Will use default authentication\n",
    "\n",
    "# Initialize Databricks clients\n",
    "@st.cache_resource\n",
    "def get_databricks_client():\n",
    "    \"\"\"Initialize Databricks MLflow deployment client\"\"\"\n",
    "    try:\n",
    "        return mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Failed to initialize Databricks client: {e}\")\n",
    "        return None\n",
    "\n",
    "@st.cache_resource\n",
    "def load_embedding_model():\n",
    "    \"\"\"Load embedding model - try Databricks first, fallback to sentence-transformers\"\"\"\n",
    "    try:\n",
    "        # Try to use Databricks embedding endpoint first\n",
    "        client = get_databricks_client()\n",
    "        if client:\n",
    "            # Test if embeddings endpoint is available\n",
    "            test_response = client.predict(\n",
    "                endpoint=\"databricks-bge-large-en\",  # Common Databricks embedding model\n",
    "                inputs={\"input\": [\"test\"]}\n",
    "            )\n",
    "            return \"databricks\"\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback to sentence-transformers\n",
    "    return SentenceTransformer(Config.FALLBACK_EMBEDDING_MODEL)\n",
    "\n",
    "@st.cache_resource\n",
    "def load_professional_data():\n",
    "    \"\"\"Load professional experience data\"\"\"\n",
    "    professional_data = {\n",
    "        \"experience\": [\n",
    "            {\n",
    "                \"role\": \"Senior Data Scientist\",\n",
    "                \"company\": \"TechCorp Inc.\",\n",
    "                \"duration\": \"2022-2024\",\n",
    "                \"description\": \"Led machine learning initiatives using Databricks, developed predictive models with MLflow, managed team of 3 junior data scientists. Implemented end-to-end ML pipelines with Delta Lake and Unity Catalog.\",\n",
    "                \"skills\": [\"Python\", \"SQL\", \"Databricks\", \"MLflow\", \"Delta Lake\", \"Unity Catalog\", \"Team Leadership\"]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"Data Engineer\", \n",
    "                \"company\": \"DataFlow Solutions\",\n",
    "                \"duration\": \"2020-2022\",\n",
    "                \"description\": \"Built data pipelines on Databricks platform, created real-time streaming analytics with Delta Live Tables, performed large-scale data processing with Apache Spark.\",\n",
    "                \"skills\": [\"Python\", \"Apache Spark\", \"Delta Live Tables\", \"SQL\", \"ETL\", \"Databricks\"]\n",
    "            }\n",
    "        ],\n",
    "        \"projects\": [\n",
    "            {\n",
    "                \"name\": \"Customer Analytics Platform on Databricks\",\n",
    "                \"description\": \"Built comprehensive customer analytics platform using Databricks Lakehouse architecture. Implemented real-time feature engineering with Delta Live Tables and MLOps workflows with MLflow.\",\n",
    "                \"tech_stack\": [\"Databricks\", \"Delta Lake\", \"MLflow\", \"Apache Spark\", \"Python\", \"Unity Catalog\"],\n",
    "                \"impact\": \"Reduced time-to-insights by 70% and improved model deployment efficiency by 50%\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Real-time Fraud Detection with Databricks\",\n",
    "                \"description\": \"Developed streaming fraud detection system using Databricks Structured Streaming and MLflow Model Registry. Processes 100k+ transactions per minute with sub-second latency.\",\n",
    "                \"tech_stack\": [\"Databricks\", \"Structured Streaming\", \"MLflow\", \"Delta Lake\", \"Python\", \"Kafka\"],\n",
    "                \"impact\": \"Reduced fraud losses by 45% and improved detection accuracy to 99.2%\"\n",
    "            }\n",
    "        ],\n",
    "        \"skills\": {\n",
    "            \"databricks_platform\": [\"Databricks Workspace\", \"Delta Lake\", \"MLflow\", \"Unity Catalog\", \"Delta Live Tables\"],\n",
    "            \"programming\": [\"Python\", \"SQL\", \"Scala\", \"R\"],\n",
    "            \"ml_frameworks\": [\"MLflow\", \"Scikit-learn\", \"TensorFlow\", \"PyTorch\", \"XGBoost\"],\n",
    "            \"data_engineering\": [\"Apache Spark\", \"Structured Streaming\", \"Delta Live Tables\", \"Apache Kafka\"],\n",
    "            \"cloud_platforms\": [\"Databricks\", \"AWS\", \"Azure\"],\n",
    "            \"mlops\": [\"MLflow\", \"Model Registry\", \"Automated Retraining\", \"A/B Testing\"]\n",
    "        },\n",
    "        \"certifications\": [\n",
    "            {\n",
    "                \"name\": \"Databricks Certified Data Engineer Professional\",\n",
    "                \"year\": \"2023\",\n",
    "                \"description\": \"Advanced certification in Databricks platform and data engineering\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Databricks Certified Machine Learning Professional\", \n",
    "                \"year\": \"2023\",\n",
    "                \"description\": \"Expert-level MLOps and machine learning on Databricks platform\"\n",
    "            }\n",
    "        ],\n",
    "        \"education\": {\n",
    "            \"degree\": \"Master of Science in Data Science\",\n",
    "            \"university\": \"University XYZ\",\n",
    "            \"year\": \"2020\",\n",
    "            \"relevant_coursework\": [\"Machine Learning\", \"Big Data Systems\", \"Statistical Modeling\"]\n",
    "        }\n",
    "    }\n",
    "    return professional_data\n",
    "\n",
    "class DatabricksRAG:\n",
    "    \"\"\"RAG implementation using Databricks native capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = get_databricks_client()\n",
    "        self.embedding_model = load_embedding_model()\n",
    "        self.professional_data = load_professional_data()\n",
    "        self.documents = []\n",
    "        self.embeddings = []\n",
    "        self.setup_knowledge_base()\n",
    "    \n",
    "    def setup_knowledge_base(self):\n",
    "        \"\"\"Create knowledge base from professional data\"\"\"\n",
    "        self.documents = self._create_documents()\n",
    "        self.embeddings = self._create_embeddings()\n",
    "    \n",
    "    def _create_documents(self) -> List[str]:\n",
    "        \"\"\"Convert professional data into searchable document chunks\"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        # Add experience entries\n",
    "        for exp in self.professional_data[\"experience\"]:\n",
    "            doc = f\"Professional Experience:\\n\"\n",
    "            doc += f\"Role: {exp['role']} at {exp['company']} ({exp['duration']})\\n\"\n",
    "            doc += f\"Description: {exp['description']}\\n\"\n",
    "            doc += f\"Key Skills: {', '.join(exp['skills'])}\"\n",
    "            documents.append(doc)\n",
    "        \n",
    "        # Add project entries\n",
    "        for proj in self.professional_data[\"projects\"]:\n",
    "            doc = f\"Project Experience:\\n\"\n",
    "            doc += f\"Project: {proj['name']}\\n\"\n",
    "            doc += f\"Description: {proj['description']}\\n\"\n",
    "            doc += f\"Technology Stack: {', '.join(proj['tech_stack'])}\\n\"\n",
    "            doc += f\"Business Impact: {proj['impact']}\"\n",
    "            documents.append(doc)\n",
    "        \n",
    "        # Add skills by category\n",
    "        for category, skills in self.professional_data[\"skills\"].items():\n",
    "            doc = f\"Technical Skills - {category.replace('_', ' ').title()}:\\n\"\n",
    "            doc += f\"Skills: {', '.join(skills)}\\n\"\n",
    "            doc += f\"Proficiency: Expert level in {category.replace('_', ' ')}\"\n",
    "            documents.append(doc)\n",
    "        \n",
    "        # Add certifications\n",
    "        if \"certifications\" in self.professional_data:\n",
    "            for cert in self.professional_data[\"certifications\"]:\n",
    "                doc = f\"Professional Certification:\\n\"\n",
    "                doc += f\"Certification: {cert['name']} ({cert['year']})\\n\"\n",
    "                doc += f\"Description: {cert['description']}\"\n",
    "                documents.append(doc)\n",
    "        \n",
    "        # Add education\n",
    "        edu = self.professional_data[\"education\"]\n",
    "        edu_doc = f\"Educational Background:\\n\"\n",
    "        edu_doc += f\"Degree: {edu['degree']} from {edu['university']} ({edu['year']})\\n\"\n",
    "        edu_doc += f\"Relevant Coursework: {', '.join(edu['relevant_coursework'])}\"\n",
    "        documents.append(edu_doc)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def _create_embeddings(self) -> List[np.ndarray]:\n",
    "        \"\"\"Create embeddings using Databricks or fallback model\"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        if self.embedding_model == \"databricks\" and self.client:\n",
    "            # Use Databricks embedding endpoint\n",
    "            try:\n",
    "                response = self.client.predict(\n",
    "                    endpoint=Config.EMBEDDING_MODEL,\n",
    "                    inputs={\"input\": self.documents}\n",
    "                )\n",
    "                embeddings = response[\"data\"]\n",
    "            except Exception as e:\n",
    "                st.warning(f\"Databricks embeddings failed, using fallback: {e}\")\n",
    "                # Fallback to sentence-transformers\n",
    "                model = SentenceTransformer(Config.FALLBACK_EMBEDDING_MODEL)\n",
    "                embeddings = model.encode(self.documents)\n",
    "        else:\n",
    "            # Use sentence-transformers\n",
    "            embeddings = self.embedding_model.encode(self.documents)\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    def retrieve_context(self, query: str, top_k: int = 3) -> str:\n",
    "        \"\"\"Retrieve relevant context for a query using similarity search\"\"\"\n",
    "        # Create query embedding\n",
    "        if self.embedding_model == \"databricks\" and self.client:\n",
    "            try:\n",
    "                query_response = self.client.predict(\n",
    "                    endpoint=Config.EMBEDDING_MODEL,\n",
    "                    inputs={\"input\": [query]}\n",
    "                )\n",
    "                query_embedding = np.array(query_response[\"data\"][0])\n",
    "            except:\n",
    "                # Fallback\n",
    "                model = SentenceTransformer(Config.FALLBACK_EMBEDDING_MODEL)\n",
    "                query_embedding = model.encode([query])[0]\n",
    "        else:\n",
    "            query_embedding = self.embedding_model.encode([query])[0]\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = []\n",
    "        for doc_embedding in self.embeddings:\n",
    "            similarity = np.dot(query_embedding, doc_embedding) / (\n",
    "                np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)\n",
    "            )\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        # Get top-k most similar documents\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        relevant_docs = []\n",
    "        for idx in top_indices:\n",
    "            relevant_docs.append(self.documents[idx])\n",
    "        \n",
    "        return \"\\n\\n\".join(relevant_docs)\n",
    "\n",
    "class DatabricksChatBot:\n",
    "    \"\"\"Chatbot using Databricks foundation models\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = get_databricks_client()\n",
    "        self.rag = DatabricksRAG()\n",
    "        \n",
    "    def generate_response(self, user_query: str, chat_history: List[Dict]) -> str:\n",
    "        \"\"\"Generate response using Databricks foundation model\"\"\"\n",
    "        \n",
    "        if not self.client:\n",
    "            return \"I'm sorry, but I'm having trouble connecting to Databricks services right now.\"\n",
    "        \n",
    "        # Retrieve relevant professional context\n",
    "        context = self.rag.retrieve_context(user_query)\n",
    "        \n",
    "        # Create system message\n",
    "        system_message = f\"\"\"You are a professional AI assistant representing a skilled data scientist and ML engineer with extensive Databricks experience. \n",
    "        \n",
    "        Your role is to discuss their professional background, technical expertise, and project experience based on the provided context.\n",
    "        \n",
    "        Professional Context:\n",
    "        {context}\n",
    "        \n",
    "        Guidelines:\n",
    "        - Be enthusiastic and professional when discussing their experience\n",
    "        - Highlight their Databricks expertise and data engineering skills\n",
    "        - Reference specific projects and achievements from the context\n",
    "        - If asked about technologies they haven't used, be honest but mention related experience\n",
    "        - Keep responses conversational but informative\n",
    "        - Focus on their unique value proposition as a Databricks expert\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare messages for foundation model\n",
    "        messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        \n",
    "        # Add recent chat history (limit to stay within context window)\n",
    "        recent_history = chat_history[-4:] if len(chat_history) > 4 else chat_history\n",
    "        messages.extend(recent_history)\n",
    "        \n",
    "        # Add current user query\n",
    "        messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "        \n",
    "        try:\n",
    "            # Call Databricks foundation model\n",
    "            response = self.client.predict(\n",
    "                endpoint=Config.FOUNDATION_MODEL_ENDPOINT,\n",
    "                inputs={\n",
    "                    \"messages\": messages,\n",
    "                    \"max_tokens\": 500,\n",
    "                    \"temperature\": 0.7\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"I apologize, but I'm having trouble processing your request. Please try again. Error: {str(e)}\"\n",
    "\n",
    "# Streamlit App\n",
    "def streamlit_app():\n",
    "    st.set_page_config(\n",
    "        page_title=\"Databricks Professional AI Assistant\",\n",
    "        page_icon=\"ðŸ”¥\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "    \n",
    "    # Header with Databricks branding\n",
    "    st.title(\"ðŸ”¥ Databricks Professional AI Assistant\")\n",
    "    st.markdown(\"*Powered by Databricks Foundation Models and MLflow*\")\n",
    "    \n",
    "    # Initialize chatbot\n",
    "    if 'chatbot' not in st.session_state:\n",
    "        with st.spinner(\"Loading Databricks-powered knowledge base...\"):\n",
    "            st.session_state.chatbot = DatabricksChatBot()\n",
    "    \n",
    "    # Initialize chat history\n",
    "    if 'messages' not in st.session_state:\n",
    "        st.session_state.messages = [\n",
    "            {\"role\": \"assistant\", \"content\": \"Hello! I'm here to discuss my professional background in data science and machine learning, with a focus on Databricks platform expertise. Feel free to ask about my experience with Databricks, MLflow, Delta Lake, or any other aspects of my professional journey!\"}\n",
    "        ]\n",
    "    \n",
    "    # Display chat history\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "    \n",
    "    # Chat input\n",
    "    if prompt := st.chat_input(\"Ask about my Databricks expertise and professional experience...\"):\n",
    "        # Add user message to chat history\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        # Display user message\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "        \n",
    "        # Generate and display assistant response\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"Thinking with Databricks AI...\"):\n",
    "                response = st.session_state.chatbot.generate_response(\n",
    "                    prompt, \n",
    "                    st.session_state.messages[:-1]\n",
    "                )\n",
    "            st.markdown(response)\n",
    "        \n",
    "        # Add assistant response to chat history\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "    # Sidebar with Databricks-focused information\n",
    "    with st.sidebar:\n",
    "        st.header(\"ðŸ”¥ Databricks Demo\")\n",
    "        st.markdown(\"\"\"\n",
    "        This chatbot showcases:\n",
    "        - **Databricks Foundation Models** for natural language generation\n",
    "        - **MLflow** for model management and deployment\n",
    "        - **Native Databricks Integration** within the platform\n",
    "        - **RAG with Databricks** for context-aware responses\n",
    "        - **Lakehouse Architecture** knowledge demonstration\n",
    "        \n",
    "        **Databricks Technologies Demonstrated:**\n",
    "        - Foundation Model APIs\n",
    "        - MLflow Deployments\n",
    "        - Delta Lake (in professional context)\n",
    "        - Unity Catalog (in experience)\n",
    "        - Delta Live Tables (in projects)\n",
    "        - Structured Streaming (in projects)\n",
    "        \"\"\")\n",
    "        \n",
    "        st.header(\"Professional Focus\")\n",
    "        st.markdown(\"\"\"\n",
    "        **Databricks Expertise:**\n",
    "        - Data Engineering with Delta Lake\n",
    "        - MLOps with MLflow\n",
    "        - Real-time Analytics\n",
    "        - Lakehouse Architecture\n",
    "        - Unity Catalog Governance\n",
    "        \"\"\")\n",
    "        \n",
    "        if st.button(\"Clear Chat History\"):\n",
    "            st.session_state.messages = [\n",
    "                {\"role\": \"assistant\", \"content\": \"Hello! I'm here to discuss my professional background in data science and machine learning, with a focus on Databricks platform expertise. Feel free to ask about my experience with Databricks, MLflow, Delta Lake, or any other aspects of my professional journey!\"}\n",
    "            ]\n",
    "            st.rerun()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c11c0b03-8b36-4f71-bca0-8a307e5e716d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Testing Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9486c95e-032e-4224-899c-9fce47ee4df0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sh streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42f08ac5-2309-4e04-a22b-6cb56cb0bcb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5429044861028069,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ProfessionalChatbotSetup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
